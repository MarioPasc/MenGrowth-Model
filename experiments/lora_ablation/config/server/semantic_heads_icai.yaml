# experiments/lora_ablation/config/server/ablation_icai.yaml
# Unified LoRA Ablation Experiment Configuration - ICAI Server
#
# This unified config supports both decoder types via decoder_type parameter:
# - "lightweight": Custom SegmentationHead (~2M params), v1 behavior
# - "original": Full SwinUNETR decoder (~30M params), v2 behavior (recommended)

experiment:
  name: lora_ablation_semantic_heads
  seed: 42
  output_dir: /media/hddb/mario/results/growth/lora_ablation_semantic_heads

paths:
  checkpoint: /media/hddb/mario/data/BrainSegFounder_finetuned_BraTS/finetuned_model_fold_0.pt
  data_root: /media/hddb/mario/data/BraTS-MEN
  # Optional: glioma data for domain shift analysis (required for --domain-features)
  glioma_root: /media/hddb/mario/data/BraTS-GLI-100

# Conservative splits for robust evaluation
data_splits:
  lora_train: 200      # Train LoRA adaptation
  lora_val: 100        # Early stopping
  probe_train: 200     # Train probes (separate from LoRA)
  test: 500            # Final evaluation

# Experimental conditions
conditions:
  - name: baseline
    lora_rank: null
    description: Frozen encoder + decoder (no adaptation)

  - name: lora_r2
    lora_rank: 2
    lora_alpha: 4
    description: LoRA rank 2

  - name: lora_r4
    lora_rank: 4
    lora_alpha: 8
    description: LoRA rank 4

  - name: lora_r8
    lora_rank: 8
    lora_alpha: 16
    description: LoRA rank 8 (recommended)

  - name: lora_r16
    lora_rank: 16
    lora_alpha: 32
    description: LoRA rank 16

  - name: lora_r32
    lora_rank: 32
    lora_alpha: 64
    description: LoRA rank 32 (saturation test)

# Training hyperparameters
training:
  max_epochs: 100
  early_stopping_patience: 25  # Increased patience for stable training
  batch_size: 4
  lr_encoder: 1.0e-4      # For LoRA params
  lr_decoder: 5.0e-4      # For decoder (if trainable)
  weight_decay: 1.0e-5
  num_workers: 4
  lora_dropout: 0.1
  gradient_clip: 1.0

  # KEY CONFIGURATION: Decoder type
  # - "lightweight": Custom SegmentationHead (~2M params), faster, v1 behavior
  # - "original": Full SwinUNETR decoder (~30M params), better gradients (recommended)
  decoder_type: "original"

  # Only used if decoder_type: "original"
  freeze_decoder: false        # Train decoder (for better gradients)
  use_semantic_heads: true     # Add auxiliary semantic prediction
  lambda_aux: 0.1              # Weight for auxiliary loss

# Segmentation loss
loss:
  lambda_dice: 1.0
  lambda_ce: 1.0
  # Auxiliary semantic loss weights (if use_semantic_heads: true)
  lambda_volume: 1.0
  lambda_location: 1.0
  lambda_shape: 1.0

# Probe evaluation
probe:
  # For both decoder types
  alpha_linear: 1.0           # Ridge regularization

  # Additional options when decoder_type: "original"
  use_mlp_probes: true        # Enable MLP probes (set false for v1 behavior)
  alpha_mlp: 1.0e-4           # MLP L2 regularization
  hidden_sizes: [256, 128]    # MLP hidden layers
  normalize_features: true
  normalize_targets: true     # KEY: normalize targets for stable training

# Feature extraction
feature_extraction:
  # - "encoder10": Single-scale 768-dim (v1 behavior)
  # - "multi_scale": layers2+3+4 (192+384+768=1344-dim, recommended)
  level: multi_scale
  batch_size: 8

# Domain analysis (glioma vs meningioma)
domain_analysis:
  enabled: true
  num_samples: 200           # Samples per domain for UMAP

# Visualization
visualization:
  umap_n_neighbors: 15
  umap_min_dist: 0.1
  color_by_semantic: true    # Color UMAP by semantic features
  show_variance_per_dim: true
  show_scatter_plots: true   # Predictions vs ground truth

# Logging
logging:
  log_every_n_steps: 10
  val_check_interval: 1.0

# Model card generation
model_card:
  enabled: true

# =============================================================================
# BACKWARD COMPATIBILITY NOTES
# =============================================================================
#
# To reproduce v1 results (lightweight decoder):
#   training:
#     decoder_type: "lightweight"
#   probe:
#     use_mlp_probes: false
#   feature_extraction:
#     level: encoder10
#
# To reproduce v2 results (original decoder, default):
#   training:
#     decoder_type: "original"
#   probe:
#     use_mlp_probes: true
#   feature_extraction:
#     level: multi_scale
